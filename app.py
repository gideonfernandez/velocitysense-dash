"""
Written by Gideon Fernandez, Founding Principal at Velocity Sense
gideonfernandez@velocitysense.com

Velocity Sense Example Dashboard
Last updated: 1 Aug 2022

"""
import time
import pathlib
import json
from datetime import datetime, timedelta
from dateutil.relativedelta import relativedelta
import dash
from dash import dash_table
import dash_bootstrap_components as dbc
from dash import dcc
from dash import html
import plotly.graph_objs as go
import plotly.express as px
import pandas as pd
from precomputing import add_stopwords
from dash.dependencies import Output, Input, State
from dateutil import relativedelta
from wordcloud import WordCloud, STOPWORDS
from sklearn.manifold import TSNE
import plotly.graph_objects as go
# import gcsfs
import calendar

YYYY = time.strftime("%Y")
NOW_TIME = datetime.now()
DAY = timedelta(5)
start_date = NOW_TIME.replace(tzinfo=None) - DAY

# date_mm = start_date.strftime('%m-%d-%Y')

mm_cal = int(start_date.strftime('%m'))
mm = calendar.month_name[mm_cal]
dd = start_date.strftime('%d')
yy = start_date.strftime('%Y')

last_updated_date = mm + ' ' + dd + ', ' + yy

embed_df = pd.read_csv(
    "data/tsne_bigram_data.csv", index_col=0
)  # Bigram embedding dataframe, with placeholder tsne values (at perplexity=3)
vects_df = pd.read_csv(
    "data/bigram_vectors.csv", index_col=0
)  # Simple averages of GLoVe 50d vectors
bigram_df = pd.read_csv("data/bigram_counts_data.csv", index_col=0)

DATA_PATH = pathlib.Path(__file__).parent.resolve()
EXTERNAL_STYLESHEETS = ["https://codepen.io/chriddyp/pen/bWLwgP.css"]
# FILENAME = "data/CEP_Reportf24ba.csv"
FILENAME = "data/bankpoc.csv"
FILENAME_PRECOMPUTED = "data/precomputed.json"
PLOTLY_LOGO = "https://i1.wp.com/velocitysense.com/wp-content/uploads/2020/04/cropped-Velocity-Sense-Transparent-Logo-Full-Resized_50.png?fit=181%2C50&ssl=1"

GLOBAL_DF = pd.read_csv(DATA_PATH.joinpath(FILENAME), header=0)
with open(DATA_PATH.joinpath(FILENAME_PRECOMPUTED)) as precomputed_file:
    PRECOMPUTED_LDA = json.load(precomputed_file)

"""
We are casting the whole column to datetime to make life easier in the rest of the code.
It isn't a terribly expensive operation so for the sake of tidyness we went this way.
"""

# GAF: Commenting out original code because any manual updates to the csv file in Excel will
# throw errors.
# GLOBAL_DF["Date received"] = pd.to_datetime(
#     GLOBAL_DF["Date received"], format="%m/%d/%Y"
# )

# GAF: This relaxes the date format conversion to allow manual updates to the csv file in Excel.
# Converts the date to yyyy-mm-dd format
GLOBAL_DF[['Date']] = GLOBAL_DF[['Date']].apply(pd.to_datetime)

GLOBAL_DF['ID'] = range(1, len(GLOBAL_DF) + 1)

"""
In order to make the graphs more useful we decided to prevent some words from being included
"""
ADDITIONAL_STOPWORDS = [
    "XXXX",
    "XX",
    "xx",
    "xxxx",
    "n't",
    "Trans Union",
    "BOA",
    "Citi",
    "account",
    # GAF: Adding my own here
    # START
    "Blank",
    "Please",
    "Find",
    # END
]
for stopword in ADDITIONAL_STOPWORDS:
    STOPWORDS.add(stopword)

"""
Proudly written for Plotly by Vildly in 2019. info@vild.ly


The aim with this dashboard is to demonstrate how Plotly's Dash framework
can be used for NLP based data analysis. The dataset is open and contains
consumer complaints from US banks ranging from 2013 to 2017.

Users can select to run the dashboard with the whole dataset (which can be slow to run)
or a smaller subset which then is evenly and consistently sampled accordingly.

Once a data sample has been selected the user can select a bank to look into by
using the dropdown or by clicking one of the bars on the right with the top 10
banks listed by number of filed complaints. Naturally bigger banks tend to end
up in this top 10 since we do not adjust for number of customers.

Once a bank has been selected a histogram with the most commonly used words for
complaints to this specific bank is shown together with a scatter plot over all
complaints, grouped by autogenerated groups.

Users can at this point do deeper inspections into interesting formations or
clusters in the scatter plot by zooming and clicking dots.

Clicking on dots in the scatter plot will display a table showing the contents
of the selected complaint (each dot is a specific complaint).

It is worth mentioning that there is also a time frame selection slider which
allows the user to look at specific time windows if there is desire to do so.

To illustrate the usefulness of this dashboard we suggest looking at how the
wordcloud and scatter plot changes from Equifax if 2017 is included in the plots
or not.

Another potentially interesting find is that Capital One has a common word
other banks seem to lack, "Macy". It would appear that Capital One at some point
teamed up with popular retailer Macy's to offer their services. This company
might have been hugely popular and thus explaining it's high frequency of occurance
in complaints, or perhaps there are other reasons explaining the data.

Regardless of what caused these two mentioned outliers, it shows how a tool
such as this can aid an analyst in finding potentially interesting things to
dig deeper into.
"""

"""
#  Somewhat helpful functions
"""


"""
# GAF Define the map
"""

# Google Cloud Platform
# Read csv report file from bucket

map_df = pd.read_csv('data/2014_us_cities.csv')
map_df.head()

map_df['text'] = map_df['name'] + '<br>Population ' + (map_df['pop']/1e6).astype(str)+' ten thousand'
limits = [(0,2),(3,10),(11,20),(21,50),(50,3000)]
colors = ["royalblue","crimson","lightseagreen","orange","lightgrey"]
cities = []
scale = 5000

map_fig = go.Figure()

for i in range(len(limits)):
    lim = limits[i]
    df_sub = map_df[lim[0]:lim[1]]
    map_fig.add_trace(go.Scattergeo(
        locationmode = 'USA-states',
        lon = df_sub['lon'],
        lat = df_sub['lat'],
        text = df_sub['text'],
        marker = dict(
            size = df_sub['pop']/scale,
            color = colors[i],
            line_color='rgb(40,40,40)',
            line_width=0.5,
            sizemode = 'area'
        ),
        name = '{0} - {1}'.format(lim[0],lim[1])))


map_fig.update_layout(
        title_text = 'Complaints Volume by City<br>(Click legend to toggle traces)',
        showlegend = True,
        geo = dict(
            scope = 'usa',
            landcolor = 'rgb(192,204,236)',
        )
    )

"""
# Map Definition End
"""


def sample_data(dataframe, float_percent):
    """
    Returns a subset of the provided dataframe.
    The sampling is evenly distributed and reproducible
    """
    print("making a local_df data sample with float_percent: %s" % (float_percent))
    return dataframe.sample(frac=float_percent, random_state=1)


def get_complaint_count_by_company(dataframe):
    """ Helper function to get complaint counts for unique banks """
    company_counts = dataframe["Bank"].value_counts()
    # we filter out all banks with less than 11 complaints for now
    company_counts = company_counts[company_counts > 10]
    values = company_counts.keys().tolist()
    counts = company_counts.tolist()
    return values, counts


def calculate_bank_sample_data(dataframe, sample_size, time_values):
    """ TODO """
    print(
        "making bank_sample_data with sample_size count: %s and time_values: %s"
        % (sample_size, time_values)
    )
    if time_values is not None:
        min_date = time_values[0]
        max_date = time_values[1]

        dataframe = dataframe[
            (dataframe["Date"] >= min_date)
            & (dataframe["Date"] <= max_date)
        ]
    company_counts = dataframe["Bank"].value_counts()
    company_counts_sample = company_counts[:sample_size]
    values_sample = company_counts_sample.keys().tolist()
    counts_sample = company_counts_sample.tolist()

    return values_sample, counts_sample


def make_local_df(selected_bank, time_values, n_selection):
    """ TODO """
    print("redrawing bank-wordcloud...")
    n_float = float(n_selection / 100)
    print("got time window:", str(time_values))
    print("got n_selection:", str(n_selection), str(n_float))
    # sample the dataset according to the slider
    local_df = sample_data(GLOBAL_DF, n_float)
    if time_values is not None:
        time_values = time_slider_to_date(time_values)
        local_df = local_df[
            (local_df["Date"] >= time_values[0])
            & (local_df["Date"] <= time_values[1])
        ]
    if selected_bank:
        local_df = local_df[local_df["Bank"] == selected_bank]
        add_stopwords(selected_bank)
    return local_df


def make_marks_time_slider(mini, maxi):
    """
    A helper function to generate a dictionary that should look something like:
    {1420066800: '2015', 1427839200: 'Q2', 1435701600: 'Q3', 1443650400: 'Q4',
    1451602800: '2016', 1459461600: 'Q2', 1467324000: 'Q3', 1475272800: 'Q4',
     1483225200: '2017', 1490997600: 'Q2', 1498860000: 'Q3', 1506808800: 'Q4'}
    """
    # GAF: original font-size is 7 for all three params. I set it to 0
    # to hide the labels for quarters
    step = relativedelta.relativedelta(months=+1)
    start = datetime(year=mini.year, month=1, day=1)
    end = datetime(year=maxi.year, month=maxi.month, day=30)
    ret = {}

    current = start
    while current <= end:
        current_str = int(current.timestamp())
        if current.month == 1:
            ret[current_str] = {
                "label": str(current.year),
                "style": {"font-weight": "bold"},
            }
        elif current.month == 4:
            ret[current_str] = {
                "label": "Q2",
                "style": {"font-weight": "lighter", "font-size": 0},
            }
        elif current.month == 7:
            ret[current_str] = {
                "label": "Q3",
                "style": {"font-weight": "lighter", "font-size": 0},
            }
        elif current.month == 10:
            ret[current_str] = {
                "label": "Q4",
                "style": {"font-weight": "lighter", "font-size": 0},
            }
        else:
            pass
        current += step
    # print(ret)
    return ret


def time_slider_to_date(time_values):
    """ TODO """
    min_date = datetime.fromtimestamp(time_values[0]).strftime("%c")
    max_date = datetime.fromtimestamp(time_values[1]).strftime("%c")
    print("Converted time_values: ")
    print("\tmin_date:", time_values[0], "to: ", min_date)
    print("\tmax_date:", time_values[1], "to: ", max_date)
    return [min_date, max_date]


def make_options_bank_drop(values):
    """
    Helper function to generate the data format the dropdown dash component wants
    """
    ret = []
    for value in values:
        ret.append({"label": value, "value": value})
    return ret

def plotly_wordcloud(data_frame):
    """A wonderful function that returns figure data for three equally
    wonderful plots: wordcloud, frequency histogram and treemap"""
    complaints_text = list(data_frame["Complaint"].dropna().values)

    if len(complaints_text) < 1:
        return {}, {}, {}

    # join all documents in corpus
    text = " ".join(list(complaints_text))

    word_cloud = WordCloud(stopwords=set(STOPWORDS), max_words=100, max_font_size=90)
    word_cloud.generate(text)

    word_list = []
    freq_list = []
    fontsize_list = []
    position_list = []
    orientation_list = []
    color_list = []

    for (word, freq), fontsize, position, orientation, color in word_cloud.layout_:
        word_list.append(word)
        freq_list.append(freq)
        fontsize_list.append(fontsize)
        position_list.append(position)
        orientation_list.append(orientation)
        color_list.append(color)

    # get the positions
    x_arr = []
    y_arr = []
    for i in position_list:
        x_arr.append(i[0])
        y_arr.append(i[1])

    # get the relative occurence frequencies
    new_freq_list = []
    for i in freq_list:
        new_freq_list.append(i * 80)

    trace = go.Scatter(
        x=x_arr,
        y=y_arr,
        textfont=dict(size=new_freq_list, color=color_list),
        hoverinfo="text",
        textposition="top center",
        hovertext=["{0} - {1}".format(w, f) for w, f in zip(word_list, freq_list)],
        mode="text",
        text=word_list,
    )

    layout = go.Layout(
        {
            "xaxis": {
                "showgrid": False,
                "showticklabels": False,
                "zeroline": False,
                "automargin": True,
                "range": [-100, 250],
            },
            "yaxis": {
                "showgrid": False,
                "showticklabels": False,
                "zeroline": False,
                "automargin": True,
                "range": [-100, 450],
            },
            "margin": dict(t=20, b=20, l=10, r=10, pad=4),
            "hovermode": "closest",
        }
    )

    wordcloud_figure_data = {"data": [trace], "layout": layout}
    word_list_top = word_list[:25]
    word_list_top.reverse()
    freq_list_top = freq_list[:25]
    freq_list_top.reverse()

    frequency_figure_data = {
        "data": [
            {
                "y": word_list_top,
                "x": freq_list_top,
                "type": "bar",
                "name": "",
                "orientation": "h",
                "marker": {"color": "#5DBCD2"}
            }
        ],
        "layout": {"height": "550", "margin": dict(t=20, b=20, l=100, r=20, pad=4)},
    }

    treemap_trace = go.Treemap(
        labels=word_list_top, parents=[""] * len(word_list_top), values=freq_list_top
    )
    treemap_layout = go.Layout({"margin": dict(t=10, b=10, l=5, r=5, pad=4)})
    treemap_figure = {"data": [treemap_trace], "layout": treemap_layout}
    return wordcloud_figure_data, frequency_figure_data, treemap_figure

# GAF: Counts the number of rows minus header record in the csv to populate
# and populates the Total Overview Dashboard card
index_df = GLOBAL_DF.index
number_of_rows = len(index_df)
number_total_activities = "{:,}".format(number_of_rows)


"""
# TOP LEVEL CARDS
"""
card1_content = [
    dbc.CardHeader(
        [
        "Organization KPI"
        ],
        style={"backgroundColor": "#5dbcd2", "color": "#f7fcf8", "text-align": "left"}
        ),
    dbc.CardBody(
        [
            html.H5("Total US Bank Complaints", className="card-title"),
            html.P(
                "18,331",
                className="card-text",
            ),
        ],
        style={"backgroundColor": "#ffffff", "color": "#5dbcd2", "text-align": "left"}
    ),
]

card2_content = [
    dbc.CardHeader(
        [
        "Service & Branding"
        ],
        style={"backgroundColor": "#5dbcd2", "color": "#f7fcf8", "text-align": "left"}
        ),
    dbc.CardBody(
        [
            html.H5("Customer Satisfication Rate", className="card-title"),
            html.P(
                "87.46%",
                className="card-text",
            ),
        ],
        style={"backgroundColor": "#ffffff", "color": "#5dbcd2", "text-align": "left"}
    ),
]

card3_content = [
    dbc.CardHeader(
        [
        "National Sales"
        ],
        style={"backgroundColor": "#5dbcd2", "color": "#f7fcf8", "text-align": "left"}
        ),
    dbc.CardBody(
        [
            html.H5("Account Conversion Rate", className="card-title"),
            html.P(
                "62.99%",
                className="card-text",
            ),
        ],
        style={"backgroundColor": "#ffffff", "color": "#5dbcd2", "text-align": "left"}
    ),
]
"""
# MAP LEVEL CARDS
"""
map_card_content_1 = [
    # dbc.CardHeader("Card header"),
    dbc.CardBody(
        [
            html.H5("Average Complaints", className="card-title"),
            html.Br(),
            html.P(
                "8,148",
                className="card-text",
            ),
        ],
        style={"backgroundColor": "#5dbcd2", "color": "#f7fcf8", "text-align": "center"}
    ),
]

map_card_content_2 = [
    dbc.CardBody(
        [
            html.H5("Highest Grossing", className="card-title"),
            html.Br(),
            html.P(
                "Equifax Inc.",
                className="card-text",
            ),
        ],
        style={"backgroundColor": "#5dbcd2", "color": "#f7fcf8", "text-align": "center"}
    ),
]

map_card_content_3 = [
    dbc.CardBody(
        [
            html.H5("Most Accounts (City, State)", className="card-title"),
            html.P(
                "Alexandria, VA (66,556)",
                className="card-text",
            ),
        ],
        style={"backgroundColor": "#5dbcd2", "color": "#f7fcf8", "text-align": "center"}
    ),
]

map_card_content_4 = [
    dbc.CardBody(
        [
            html.H5("Total Accounts Created", className="card-title"),
            html.Br(),
            html.P(
                "433,021",
                className="card-text",
            ),
        ],
        style={"backgroundColor": "#5dbcd2", "color": "#f7fcf8", "text-align": "center"}
    ),
]


"""
#  Page layout and contents

In an effort to clean up the code a bit, we decided to break it apart into
sections. For instance: LEFT_COLUMN is the input controls you see in that gray
box on the top left. The body variable is the overall structure which most other
sections go into. This just makes it ever so slightly easier to find the right
spot to add to or change without having to count too many brackets.
"""

NAVBAR = dbc.Navbar(
    children=[
        html.A(
            # Use row and col to control vertical alignment of logo / brand
            dbc.Row(
                [
                    dbc.Col(html.Img(src=PLOTLY_LOGO, height="30px")),
                    dbc.Col(
                        dbc.NavbarBrand("Example Dashboard (US Banks Data Analytics)", className="ml-2", style={"color": "#443741"})
                    ),
                ],
                align="center",
                # no_gutters=True,
            ),
            href="https://www.velocitysense.com",
        )
    ],
    color="#f9f9f9",
    light=True,
    sticky="top",
)

# LEFT_COLUMN = dbc.Jumbotron(
#     [
#         html.H4(children="Select bank & dataset size", className="display-5"),
#         html.Hr(className="my-2"),
#         html.Label("Select percentage of dataset", className="lead"),
#         html.P(
#             "(Lower is faster. Higher is more precise)",
#             style={"fontSize": 10, "font-weight": "lighter"},
#         ),
#         dcc.Slider(
#             id="n-selection-slider",
#             min=1,
#             max=100,
#             step=1,
#             marks={
#                 0: "0%",
#                 10: "",
#                 20: "20%",
#                 30: "",
#                 40: "40%",
#                 50: "",
#                 60: "60%",
#                 70: "",
#                 80: "80%",
#                 90: "",
#                 100: "100%",
#             },
#             # GAF Default Slider size population
#             value=50,
#         ),
#         html.Label("Select a bank", style={"marginTop": 50}, className="lead"),
#         html.P(
#             "(You can use the dropdown or click the barchart on the right)",
#             style={"fontSize": 10, "font-weight": "lighter"},
#         ),
#         dcc.Dropdown(
#             id="bank-drop", clearable=False, style={"marginBottom": 50, "font-size": 12}
#         ),
#         html.Label("Select time frame", className="lead"),
#         html.Div(dcc.RangeSlider(id="time-window-slider"), style={"marginBottom": 50}),
#         html.P(
#             "(You can define the time frame down to month granularity)",
#             style={"fontSize": 10, "font-weight": "lighter"},
#         ),
#     ]
# )

LEFT_COLUMN = html.Div(
    dbc.Container(
        [
            # html.Label(children="Select bank & dataset size", className="lead"),
            html.H4(
                "Select bank & dataset size",
                # className="display-5",
            ),
            html.Hr(className="my-2"),
            html.Label("Select percentage of dataset", className="lead"),
            html.P(
                "(Lower is faster. Higher is more precise)",
                style={"fontSize": 10, "font-weight": "lighter"},
            ),
            dcc.Slider(
                id="n-selection-slider",
                min=1,
                max=100,
                step=1,
                marks={
                    0: "0%",
                    10: "",
                    20: "20%",
                    30: "",
                    40: "40%",
                    50: "",
                    60: "60%",
                    70: "",
                    80: "80%",
                    90: "",
                    100: "100%",
                },
                # GAF Default Slider size population
                value=50,
            ),


            html.Label("Select a bank", style={"marginTop": 50}, className="lead"),
            html.P(
                "(You can use the dropdown or click the barchart on the right)",
                style={"fontSize": 10, "font-weight": "lighter"},
            ),
            dcc.Dropdown(
                id="bank-drop", clearable=False, style={"marginBottom": 50, "font-size": 12}
            ),
            html.Label("Select time frame", className="lead"),
            html.P(
                "(You can define the timeframe down to month granularity)",
                style={"fontSize": 10, "font-weight": "lighter"},
            ),
            dcc.RangeSlider(0, 20, 1, value=[5, 15], id='time-window-slider'),
        ],
        fluid=True,
        className="py-3",
    ),
    className="p-3 bg-light rounded-3",
)

WORDCLOUD_PLOTS = [
    dbc.CardHeader(html.H5("Most frequently used words in Bank Complaints"), style={"backgroundColor": "#8b66d2", "color": "white"}),
    dbc.Alert(
        "Select an Organization to begin",
        id="no-data-alert",
        color="warning",
        style={"display": "none"},
    ),
    dbc.CardBody(
        [
            dbc.Row(
                [
                    dbc.Col(
                        dcc.Loading(
                            id="loading-frequencies",
                            children=[dcc.Graph(id="frequency_figure")],
                            type="default",
                        )
                    ),
                    dbc.Col(
                        [
                            dcc.Tabs(
                                id="tabs",
                                children=[
                                    dcc.Tab(
                                        label="Treemap",
                                        children=[
                                            dcc.Loading(
                                                id="loading-treemap",
                                                children=[dcc.Graph(id="bank-treemap")],
                                                type="default",
                                            )
                                        ],
                                    ),
                                    dcc.Tab(
                                        label="Wordcloud",
                                        children=[
                                            dcc.Loading(
                                                id="loading-wordcloud",
                                                children=[
                                                    dcc.Graph(id="bank-wordcloud")
                                                ],
                                                type="default",
                                            )
                                        ],
                                    ),
                                ],
                            )
                        ],
                        md=8,
                    ),
                ]
            )
        ]
    ),
]

TOP_ORGS_PLOT = [
    dbc.CardHeader(
        [
        html.H5("Top 10 Banks by Number of Complaints")
        ],
        style={"backgroundColor": "#8b66d2", "color": "white", "text-align": "left"}
        ),
    dbc.CardBody(
        [
            dcc.Loading(
                id="loading-banks-hist",
                children=[
                    dbc.Alert(
                        "Not enough data to render this plot, please adjust the filters",
                        id="no-data-alert-bank",
                        color="warning",
                        style={"display": "none"},
                    ),
                    dcc.Graph(id="bank-sample"),
                ],
                type="default",
            )
        ],
        style={"marginTop": 0, "marginBottom": 0},
    ),
]

ORG_DATATABLE = [
    dbc.CardHeader(
        [
        html.H5("Detailed Bank Complaints View")
        ],
        style={"backgroundColor": "#8b66d2", "color": "white", "text-align": "left"}
        ),
    dbc.CardBody(
        [
        dash_table.DataTable(
            id='datatable-interactivity',
            page_size=20,
            # columns =  [{"name": i, "id": i,} for i in (GLOBAL_DF.columns)],
            sort_mode='multi',
            sort_action='native',
            style_table={
                        'height': '600px',
                        'overflowY': 'auto',
                        'textAlign': 'left',
                        },
            style_cell={
                        'textAlign': 'left',
                        'whiteSpace': 'normal',
                        'height': 'auto',
                        'lineHeight': '15px',
                        # 'minWidth': '180px',
                        'width': '180px',
                        'maxWidth': '180px',
                        'fontSize':12,
                        'font-family':'sans-serif',
                        },
            style_header={
                'backgroundColor': '#d0d0d0',
                'color': '#8b66d2',
                'fontWeight': 'bold'
            },
            style_data_conditional=[
                        {
                        'if': {'row_index': 'odd'},
                        'backgroundColor': '#ededed'
                        },
                    ],
            style_cell_conditional=[
                        {
                        'if': {'column_id': ['ID','Date']},
                        'textAlign': 'right',
                        'width': '100px'
                        },
                    ],
                ),
        ],
        style={"marginTop": 0, "marginBottom": 0},
        # fixed_rows={'headers': True},
    ),
    html.Div(id='intermediate-value', style={'display': 'none'}),
]

IMPRESSIONS_MAP = [
    dbc.CardHeader(
        [
        html.H5("All US Bank Complaints Received")
        ],
        style={"backgroundColor": "#8b66d2", "color": "white", "text-align": "left"}
        ),
    dbc.CardBody(
        [
        dcc.Graph(figure=map_fig, style={"height": 700})
        ]
        )
]

BODY = dbc.Container(
    [
        dbc.Row([
            dbc.Col(html.H6([
                "Last updated: ",
                last_updated_date
                ]), style={"color": "#443741", "marginTop": 10}, className="mb-2")
        ]),
        # dbc.Row([
        #     dbc.Col(html.Br(), className="mb-2")
        # ]),
        dbc.Row(
            [
                dbc.Col(dbc.Card(card1_content)),
                dbc.Col(
                    dbc.Card(card2_content)
                ),
                dbc.Col(dbc.Card(card3_content)),
            ],
            className="mb-4",
            ),
        dbc.Row(
            [
                dbc.Col(LEFT_COLUMN, md=4, align="center"),
                dbc.Col(dbc.Card(TOP_ORGS_PLOT), md=8),
            ],
            style={"marginTop": 30},
        ),
        dbc.Card(WORDCLOUD_PLOTS),
        dbc.Card(ORG_DATATABLE, style={"marginTop": 30}),
    ],
    className="mt-12",
)

BOTTOM = dbc.Container(
    [
        dbc.Row(
            [
                dbc.Col(dbc.Card(map_card_content_1)),
                dbc.Col(dbc.Card(map_card_content_2)),
                dbc.Col(dbc.Card(map_card_content_3)),
                dbc.Col(dbc.Card(map_card_content_4)),
            ],
            style={"marginTop": 30},
            # no_gutters=False,
        ),
        dbc.Card(IMPRESSIONS_MAP, style={"marginTop": 30}),
        dbc.Row([
            dbc.Col(html.Br(), className="mb-2")
        ]),
    ],
    className="mt-12",
)

app = dash.Dash(__name__, external_stylesheets=[dbc.themes.BOOTSTRAP])
server = app.server  # for Heroku deployment
app.title = 'Velocity Sense'

app.layout = html.Div(children=[NAVBAR, BODY, BOTTOM])

"""
#  Callbacks
"""

@app.callback(
    [
        Output("time-window-slider", "marks"),
        Output("time-window-slider", "min"),
        Output("time-window-slider", "max"),
        Output("time-window-slider", "step"),
        Output("time-window-slider", "value"),
    ],
    [Input("n-selection-slider", "value")],
)
def populate_time_slider(value):
    """
    Depending on our dataset, we need to populate the time-slider
    with different ranges. This function does that and returns the
    needed data to the time-window-slider.
    """
    value += 0
    min_date = GLOBAL_DF["Date"].min()
    max_date = GLOBAL_DF["Date"].max()

    print('ZOUK MIN_DATE: ', min_date)
    print('ZOUK MAX_DATE: ', max_date)
    marks = make_marks_time_slider(min_date, max_date)

    min_epoch = list(marks.keys())[0]
    max_epoch = list(marks.keys())[-1]

    return (
        marks,
        min_epoch,
        max_epoch,
        (max_epoch - min_epoch) / (len(list(marks.keys())) * 3),
        [min_epoch, max_epoch],
)

@app.callback(
    Output("bank-drop", "options"),
    [Input("time-window-slider", "value"), Input("n-selection-slider", "value")],
)
def populate_bank_dropdown(time_values, n_value):
    """ TODO """
    print("bank-drop: TODO USE THE TIME VALUES AND N-SLIDER TO LIMIT THE DATASET")
    if time_values is not None:
        pass
    n_value += 1
    bank_names, counts = get_complaint_count_by_company(GLOBAL_DF)
    counts.append(1)
    return make_options_bank_drop(bank_names)

@app.callback(
    [Output("bank-sample", "figure"), Output("no-data-alert-bank", "style")],
    [Input("n-selection-slider", "value"), Input("time-window-slider", "value")],
)
def update_bank_sample_plot(n_value, time_values):
    """ TODO """
    print("redrawing bank-sample...")
    print("\tn is:", n_value)
    print("\ttime_values is:", time_values)

    if time_values is None:
        return [{}, {"display": "block"}]
    n_float = float(n_value / 100)
    bank_sample_count = 10
    local_df = sample_data(GLOBAL_DF, n_float)
    min_date, max_date = time_slider_to_date(time_values)
    values_sample, counts_sample = calculate_bank_sample_data(
        local_df, bank_sample_count, [min_date, max_date]
    )
    data = [
        {
            "x": values_sample,
            "y": counts_sample,
            "text": values_sample,
            "textposition": "auto",
            "type": "bar",
            "name": "",
            "marker": {"color": "#5DBCD2"},
            "textfont": dict(color="white")
        }
    ]
    layout = {
        "autosize": False,
        "margin": dict(t=10, b=10, l=40, r=0, pad=4),
        "xaxis": {"showticklabels": False},
    }
    print("redrawing bank-sample...done")
    return [{"data": data, "layout": layout}, {"display": "none"}]


@app.callback(
    [
        Output("bank-wordcloud", "figure"),
        Output("frequency_figure", "figure"),
        Output("bank-treemap", "figure"),
        Output("no-data-alert", "style"),
        Output("intermediate-value", "children"),
    ],
    [
        Input("bank-drop", "value"),
        Input("time-window-slider", "value"),
        Input("n-selection-slider", "value"),
    ],
)
def update_wordcloud_plot(value_drop, time_values, n_selection):
    """ Callback to rerender wordcloud plot """
    local_df = make_local_df(value_drop, time_values, n_selection)

    df_1 = make_local_df(value_drop, time_values, n_selection)

    df_1 = df_1[[
                'ID',
                'Date',
                'Bank',
                # 'Event Name',
                # 'Event Status',
                # 'Name',
                'Interaction',
                'Complaint'
                ]]

    wordcloud, frequency_figure, treemap = plotly_wordcloud(local_df)

    alert_style = {"display": "none"}

    if (wordcloud == {}) or (frequency_figure == {}) or (treemap == {}):
        alert_style = {"display": "block"}
    print("redrawing bank-wordcloud...done")

    return (wordcloud, frequency_figure, treemap, alert_style,
        df_1.to_json(date_format='iso', orient='split'
            ))

# GAF: Callback to update datatable based on treemap or frequency-figure selected
@app.callback(
    [
        Output("datatable-interactivity", "data"),
        Output("datatable-interactivity", "columns"),
    ],
    [
        Input("frequency_figure", "clickData"),
        # Input("bank-treemap", "clickData"),
        Input("intermediate-value", "children"),
    ],
    [
        State("bank-drop", "value"),
    ]
)
def update_datatable_bar(clickData, jsonified_cleaned_data, value):
    # Section 0: Pre-populated datatable when app is initiated
    if clickData is None:
        default_df = GLOBAL_DF[GLOBAL_DF['Bank']==value]

        default_df['Date'] = default_df['Date'].dt.strftime('%m-%d-%Y')

        default_df = default_df[[
                    'ID',
                    'Date',
                    'Bank',
                    # 'Event Name',
                    # 'Event Status',
                    # 'Name',
                    'Interaction',
                    'Complaint'
                    ]]

        default_df = default_df.rename(columns={
            'Bank': 'Bank',
            'Complaint': 'Complaint'
            })

        dt_col_param_default = []

        for col in default_df.columns:
            dt_col_param_default.append({"name": str(col), "id": str(col)})

        data_ob_default = default_df.to_dict('rows')
        return (data_ob_default, dt_col_param_default)

    # Section 1: Capture the WORD data from the selected graph
    ctx = dash.callback_context
    inputs = ctx.inputs

    stepone = [
       inputs["frequency_figure.clickData"]["points"][0]["y"]
            ]

    print('ZOUK STEPONE', stepone)

    # Section 2: Clean the WORD data and grab the first or second word to compare
    steptwo = str(stepone).strip('[]')
    print('ZOUK STEPTWO VALUE', steptwo)

    stepthree = str(steptwo).strip("'")
    print('ZOUK STEPTHREE VALUE', stepthree)

    # Section 3: Prepare the dataframe that was json'd and stored from the hidden div

    dff = pd.read_json(jsonified_cleaned_data, orient='split')

    # Section 4: Filter dataframe based on WORD selected
    if len(stepthree.split()) > 1: # has more than 1 word, check against the first word
        (stepfour, secondword) = stepthree.split(maxsplit=1)
        dff = dff[dff['Complaint'].str.contains(stepfour, case=False, na=False)]
    else: # Use this single word
        dff = dff[dff['Complaint'].str.contains(stepthree, case=False, na=False)]

    dff['Date'] = dff['Date'].dt.strftime('%m-%d-%Y')

    # Section 5: Prepare and load the datatable
    dff = dff.rename(columns={
        'Bank': 'Bank',
        'Complaint': 'Barriers'
        })

    dt_col_param = []

    for col in dff.columns:
        dt_col_param.append({"name": str(col), "id": str(col)})

    data_ob = dff.to_dict('rows')

    return (data_ob, dt_col_param)

@app.callback(Output("bank-drop", "value"), [Input("bank-sample", "clickData")])
def update_bank_drop_on_click(value):
    """ TODO """
    if value is not None:
        selected_bank = value["points"][0]["x"]
        return selected_bank
    return "Ditech Financial LLC"


if __name__ == "__main__":
    app.run_server(debug=False)